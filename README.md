# Comparative Analysis: Human vs. Machine Learning Model Performance in Textured Image Classification.

We conducted a survey to see how well humans perform in image classification tasks compared to a machine learning model operating in a similar setup.

On the first page of the survey, we showed samples featuring sets of images of synthetic fibers. These images were generated artificially, and you can find the code responsible for this in the repository - 
<img width="859" alt="image" src="https://github.com/rahultejagorantala/Image_Classification_Survey/assets/101026703/79159259-722e-4554-a01f-c52322405336">

The second page presented various images, and participants were asked to label each image. The results were then displayed in the plot below.
<img width="640" alt="image" src="https://github.com/rahultejagorantala/Image_Classification_Survey/assets/101026703/c3a0b73d-f23f-400f-be3f-3014980b3958">

![image](https://github.com/rahultejagorantala/Image_Classification_Survey/assets/101026703/0fd3a0be-8440-4070-b3aa-f097458e31ff)



The main takeaway from our study was that when images from both classes are very close to each other (as in our case), humans struggle to differentiate effectively. However, with more attention and time, humans can come closer to matching the performance of a machine learning model. As image similarities increase further, it's expected that machine learning models will significantly outperform humans in identifying patterns within the images.
